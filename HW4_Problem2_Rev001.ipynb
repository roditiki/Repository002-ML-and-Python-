{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/roditiki/Repository002-ML-and-Python-/blob/main/HW4_Problem2_Rev001.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 465,
      "id": "d9710eb4",
      "metadata": {
        "id": "d9710eb4"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import seaborn as sns\n",
        "from sklearn import metrics\n",
        "from sklearn.linear_model import LogisticRegressionCV\n",
        "from sklearn import metrics\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "from sklearn import svm, datasets\n",
        "from sklearn.svm import LinearSVR\n",
        "from sklearn.svm import SVR\n",
        "import csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 466,
      "id": "ca345e52",
      "metadata": {
        "id": "ca345e52"
      },
      "outputs": [],
      "source": [
        "def get_confusion_matrix(cnf_matrix):\n",
        "    class_names=[0,1] # name of classes\n",
        "    fig, ax = plt.subplots()\n",
        "    tick_marks = np.arange(len(class_names))\n",
        "    plt.xticks(tick_marks, class_names)\n",
        "    plt.yticks(tick_marks, class_names)\n",
        "    # create heatmap\n",
        "    sns.heatmap(pd.DataFrame(cnf_matrix), annot=True, cmap=\"YlGnBu\" ,fmt='g')\n",
        "    ax.xaxis.set_label_position(\"top\")\n",
        "    plt.tight_layout()\n",
        "    plt.title('Confusion matrix', y=1.1)\n",
        "    plt.ylabel('Actual label')\n",
        "    plt.xlabel('Predicted label')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 467,
      "id": "5616aab7",
      "metadata": {
        "id": "5616aab7"
      },
      "outputs": [],
      "source": [
        "def get_results(y_test, Y_pred):\n",
        "    acc = metrics.accuracy_score(y_test, Y_pred)\n",
        "    pre = metrics.precision_score(y_test, Y_pred)\n",
        "    rec = metrics.recall_score(y_test, Y_pred)\n",
        "    print(\"Accuracy:\",metrics.accuracy_score(y_test, Y_pred))\n",
        "    print(\"Precision:\",metrics.precision_score(y_test, Y_pred))\n",
        "    print(\"Recall:\",metrics.recall_score(y_test, Y_pred))\n",
        "    return [acc*100.0, pre*100.0, rec*100.0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 468,
      "id": "01e49763",
      "metadata": {
        "id": "01e49763"
      },
      "outputs": [],
      "source": [
        "def GaussianNB_model_training(X_train, y_train, X_test, y_test):\n",
        "    classifier = GaussianNB()\n",
        "    classifier.fit(X_train, y_train)\n",
        "    Y_pred = classifier.predict(X_test)\n",
        "    cnf_matrix = confusion_matrix(y_test, Y_pred)\n",
        "    return cnf_matrix, Y_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 469,
      "id": "9faa0ef5",
      "metadata": {
        "id": "9faa0ef5"
      },
      "outputs": [],
      "source": [
        "def logist_model_training_pca(X, Y):\n",
        "    n=X.shape[1]\n",
        "    acc_list=[]\n",
        "    recall_list=[]\n",
        "    precision_list=[]\n",
        "    k_list=[]\n",
        "    for i in range(n):\n",
        "        print(\"K = \"+ str(i+1))\n",
        "        X_train_pca_log, X_test_pca_log, y_train_pca_log, y_test_pca_log = train_test_split(X, Y, test_size=0.20, random_state=9999)       \n",
        "        pca = PCA(n_components=i+1)\n",
        "        #principalComponents = pca.fit_transform(X)\n",
        "        X_train_pca_log= pca.fit_transform(X_train_pca_log)\n",
        "        X_test_pca_log= pca.transform(X_test_pca_log)        \n",
        "        #classifier = LogisticRegression(penalty='l2', C=1, solver = 'lbfgs')\n",
        "        classifier = LogisticRegression(random_state=9)\n",
        "        classifier.fit(X_train_pca_log, y_train_pca_log)\n",
        "        Y_pred_pca_log = classifier.predict(X_test_pca_log)\n",
        "        re = get_results(y_test_pca_log, Y_pred_pca_log)\n",
        "        acc_list.append(re[0])\n",
        "        precision_list.append(re[1])\n",
        "        recall_list.append(re[2])\n",
        "        k_list.append(i+1)\n",
        "    high_acc = max(acc_list)\n",
        "    high_acc_k=acc_list.index(max(acc_list))+1\n",
        "    print(\"----------------\")\n",
        "    print(\"Highest Classification Accuracy Achieved: \"+ str(high_acc)+\" for K␣number = \"+str(high_acc_k))\n",
        "    return k_list, acc_list, precision_list, recall_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 470,
      "id": "0e3ad1fb",
      "metadata": {
        "id": "0e3ad1fb"
      },
      "outputs": [],
      "source": [
        "def SVM_model_training_pca(X, Y):\n",
        "    n=X.shape[1]\n",
        "    acc_list=[]\n",
        "    recall_list=[]\n",
        "    precision_list=[]\n",
        "    k_list=[]\n",
        "    for i in range(n):\n",
        "        print(\"K = \"+ str(i+1))\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.20, random_state=9999)\n",
        "        pca = PCA(n_components=i+1)\n",
        "        X_train = pca.fit_transform(X_train)\n",
        "        X_test = pca.transform(X_test)\n",
        "        #classifier = GaussianNB()\n",
        "        classifier = svm.LinearSVC()       \n",
        "        classifier.fit(X_train, y_train)\n",
        "        Y_pred = classifier.predict(X_test)\n",
        "        re = get_results(y_test, Y_pred)\n",
        "        acc_list.append(re[0])\n",
        "        precision_list.append(re[1])\n",
        "        recall_list.append(re[2])\n",
        "        k_list.append(i+1)\n",
        "    high_acc = max(acc_list)\n",
        "    high_acc_k=acc_list.index(max(acc_list))+1\n",
        "    print(\"----------------\")\n",
        "    print(\"Highest Classification Accuracy Achieved: \"+ str(high_acc)+\" for K␣number = \"+str(high_acc_k))\n",
        "    return k_list, acc_list, precision_list, recall_list\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def SVR_model_training_pca(X, Y):\n",
        "    n=X.shape[1]\n",
        "    acc_list=[]\n",
        "    recall_list=[]\n",
        "    precision_list=[]\n",
        "    k_list=[]\n",
        "    for i in range(n):\n",
        "        print(\"K = \"+ str(i+1))\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.20, random_state=9999)\n",
        "        pca = PCA(n_components=i+1)\n",
        "        X_train = pca.fit_transform(X_train)\n",
        "        X_test = pca.transform(X_test)\n",
        "\n",
        "        # SUPPORT VECTOR REGRESSION command # Select one option of kernel for simulation:\n",
        "        classifier = svm.SVR(kernel=\"rbf\", gamma=0.1, C=100, epsilon=0.1)  \n",
        "        #svm.SVR(*, kernel='rbf', degree=3, gamma='scale', coef0=0.0, tol=0.001, C=1.0, epsilon=0.1, shrinking=True, cache_size=200, verbose=False, max_iter=-1)[source]¶    \n",
        "        #classifier = svm.SVR(kernel=\"linear\", C=100, gamma=\"auto\")  \n",
        "        #classifier = svm.SVR(kernel=\"poly\", C=100, gamma=\"auto\", degree=3, epsilon=0.1, coef0=1)  \n",
        "        #classifier = svm.LinearSVR(C=100, gamma=0.1, epsilon=0.1) to be fixed         \n",
        "        classifier.fit(X_train, y_train)\n",
        "        Y_pred = classifier.predict(X_test)\n",
        "        re = get_results(y_test, Y_pred)\n",
        "        acc_list.append(re[0])\n",
        "        precision_list.append(re[1])\n",
        "        recall_list.append(re[2])\n",
        "        k_list.append(i+1)\n",
        "    high_acc = max(acc_list)\n",
        "    high_acc_k=acc_list.index(max(acc_list))+1\n",
        "    print(\"----------------\")\n",
        "    print(\"Highest Classification Accuracy Achieved: \"+ str(high_acc)+\" for K␣number = \"+str(high_acc_k))\n",
        "    return k_list, acc_list, precision_list, recall_list"
      ],
      "metadata": {
        "id": "3mEAIRz6PXoE"
      },
      "id": "3mEAIRz6PXoE",
      "execution_count": 471,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 472,
      "id": "954e7442",
      "metadata": {
        "id": "954e7442"
      },
      "outputs": [],
      "source": [
        "def plot_result_with_k(k_list, acc_list, precision_list, recall_list):\n",
        "    plt.plot(k_list, acc_list, label = \"Accuracy\")\n",
        "    plt.plot(k_list, precision_list, label = \"Precision\")\n",
        "    plt.plot(k_list, recall_list, label = \"Recall\")\n",
        "    plt.legend()\n",
        "    plt.title('Plotting classification accuracy, precision, and recall over a␣different number of Ks')\n",
        "    plt.ylabel('Value')\n",
        "    plt.xlabel('K')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 473,
      "id": "b6317279",
      "metadata": {
        "id": "b6317279"
      },
      "outputs": [],
      "source": [
        "    #Dataset Reading\n",
        "#from sklearn.datasets import load_breast_cancer\n",
        "#breast = load_breast_cancer()\n",
        "#X = breast.data\n",
        "#print(X.shape)\n",
        "#Y = breast.target\n",
        "#breast_input = pd.DataFrame(X)\n",
        "#breast_input.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "    #Dataset Reading\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('https://drive.google.com/drive/folders/1SjVikAoQ-a3P7G0Ma8z0fpwTtBUaY0bx')\n",
        "ls\n",
        "\n",
        "cd gdrive/MyDrive/UNCC/Fall22/Intro\\ to\\ ML/Homeworks/HW1\n",
        "\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "df = pd.read_csv (r,\"C:\\Users\\rodit\\OneDrive\\Desktop\\MachineLearning\\Datasets\\Housing.csv\")\n",
        "#',encoding='unicode_escape',engine='python',on_bad_lines='skip')\n",
        "print(\"CSV File Shape\")\n",
        "print(df.shape)\n",
        "df.head()\n",
        "\n",
        "svar_list = ['mainroad', 'guestroom', 'basement', 'hotwaterheating','airconditioning', 'prefarea']\n",
        "\n",
        "def binary_mapping(x):\n",
        "     return x.map({'yes':1, 'no':0})\n",
        "     df[svar_list] = df[svar_list].apply(binary_mapping)\n",
        "     df.head()\n",
        "\n",
        "def get_modified_inputs(X):\n",
        "     x_0 = np.ones([X.shape[0], 1])\n",
        "     inputs= np.concatenate((x_0, X), axis = -1)\n",
        "     return inputs\n",
        "\n",
        "num_vars = ['area', 'bedrooms', 'bathrooms', 'stories', 'parking','price']\n",
        "#num_vars = ['area', 'bedrooms', 'bathrooms', 'stories','price']\n",
        "data = df[num_vars]\n",
        "target_column = 'price' # Target to predict\n",
        "\n",
        "inputs = data.drop([target_column], axis=1).to_numpy()\n",
        "targets = data[[target_column]].to_numpy()\n",
        "print(\"Input shape: \"+ str(inputs.shape))\n",
        "print(\"Target shape: \"+ str(targets.shape))\n",
        "\n",
        "inputs = get_modified_inputs(inputs)\n",
        "print(inputs.shape)\n",
        "\n",
        "X = inputs\n",
        "Y = target_column\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130
        },
        "id": "bBCq1xcbkU-V",
        "outputId": "4e1ce3e7-aa37-46f3-f1d8-bee17de4edf1"
      },
      "id": "bBCq1xcbkU-V",
      "execution_count": 477,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-477-ee4a243a6748>\"\u001b[0;36m, line \u001b[0;32m10\u001b[0m\n\u001b[0;31m    df = pd.read_csv (r,\"C:\\Users\\rodit\\OneDrive\\Desktop\\MachineLearning\\Datasets\\Housing.csv\")\u001b[0m\n\u001b[0m                                                                                              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m (unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \\UXXXXXXXX escape\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e22a1936",
      "metadata": {
        "id": "e22a1936"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.20, random_state=42)\n",
        "sc_X = StandardScaler()\n",
        "X_train = sc_X.fit_transform(X_train)\n",
        "X_test = sc_X.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0c57c0f4",
      "metadata": {
        "id": "0c57c0f4"
      },
      "outputs": [],
      "source": [
        "sc_X = StandardScaler()\n",
        "X = sc_X.fit_transform(breast_input)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6dfd5872",
      "metadata": {
        "id": "6dfd5872"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Problem 1a - LogisticRegression\n",
        "k_list, acc_list, precision_list, recall_list = logist_model_training_pca(X, Y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "84d62acb",
      "metadata": {
        "id": "84d62acb"
      },
      "outputs": [],
      "source": [
        "plot_result_with_k(k_list, acc_list, precision_list, recall_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "31614f21",
      "metadata": {
        "id": "31614f21"
      },
      "outputs": [],
      "source": [
        "## Problem 1b - SVM \n",
        "#k_list, acc_list, precision_list, recall_list = GaussianNB_model_training_pca(X,Y)\n",
        "k_list, acc_list, precision_list, recall_list = SVM_model_training_pca(X,Y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c3ad8bfa",
      "metadata": {
        "id": "c3ad8bfa"
      },
      "outputs": [],
      "source": [
        "plot_result_with_k(k_list, acc_list, precision_list, recall_list)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Problem 2b - svm.SVR (support vector regression) \n",
        "k_list, acc_list, precision_list, recall_list = SVR_model_training_pca(X,Y)"
      ],
      "metadata": {
        "id": "c-E1M-A_dU98"
      },
      "id": "c-E1M-A_dU98",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_result_with_k(k_list, acc_list, precision_list, recall_list)"
      ],
      "metadata": {
        "id": "JFFWcTC-dolu"
      },
      "id": "JFFWcTC-dolu",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "celltoolbar": "Tags",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}